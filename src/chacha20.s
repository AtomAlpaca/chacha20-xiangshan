	.option nopic
	.text
	.align	1
	.globl	_Z8chacha20P10chacha_bufPKj
	.type	_Z8chacha20P10chacha_bufPKj, @function
_Z8chacha20P10chacha_bufPKj:
.LFB22951:
	.cfi_startproc
	addi	sp,sp,-144
	.cfi_def_cfa_offset 144
	mv	a5,sp
	sd	s6,80(sp)
	li	a2,64
	.cfi_offset 22, -64
	mv	s6,a0
	mv	a0,a5
	sd	s0,128(sp)
	sd	s1,120(sp)
	sd	s2,112(sp)
	sd	s3,104(sp)
	sd	s4,96(sp)
	sd	s5,88(sp)
	sd	s7,72(sp)
	sd	ra,136(sp)
	.cfi_offset 8, -16
	.cfi_offset 9, -24
	.cfi_offset 18, -32
	.cfi_offset 19, -40
	.cfi_offset 20, -48
	.cfi_offset 21, -56
	.cfi_offset 23, -72
	.cfi_offset 1, -8
	mv	s7,a1
	call	memcpy
	lui	t4,%hi(.LANCHOR0)
	lui	t3,%hi(.LANCHOR0+32)
	lui	t1,%hi(.LANCHOR0+16)
	li	a4,4
	mv	a5,a0
	li	t2,10
	addi	a7,sp,16
	addi	a6,sp,48
	addi	a2,sp,32
	addi	t4,t4,%lo(.LANCHOR0)
	addi	t3,t3,%lo(.LANCHOR0+32)
	addi	t1,t1,%lo(.LANCHOR0+16)
	li	t0,16
	li	s5,20
	li	s4,12
	li	s3,24
	li	s2,8
	li	s1,25
	li	s0,7
	vsetvli	a3,a4,e32,m1
.L2:
	vsetvli	a1,a3,e32,m1
	vlwu.v	v2,0(a7)
	vlwu.v	v1,0(a5)
	vadd.vv	v1,v1,v2
	vsw.v	v1,0(a5)
	vsetvli	a1,a4,e32,m1
	vlwu.v	v2,0(a5)
	vlwu.v	v1,0(a6)
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,t0
	vsll.vx	v1,v1,t0
	vor.vv	v1,v2,v1
	vsw.v	v1,0(a6)
	vsetvli	a1,a3,e32,m1
	vlwu.v	v2,0(a6)
	vlwu.v	v1,0(a2)
	vadd.vv	v1,v1,v2
	vsw.v	v1,0(a2)
	vsetvli	a1,a4,e32,m1
	vlwu.v	v2,0(a2)
	vlwu.v	v1,0(a7)
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,s5
	vsll.vx	v1,v1,s4
	vor.vv	v1,v2,v1
	vsw.v	v1,0(a7)
	vsetvli	a1,a3,e32,m1
	vlwu.v	v2,0(a7)
	vlwu.v	v1,0(a5)
	vadd.vv	v1,v1,v2
	vsw.v	v1,0(a5)
	vsetvli	a1,a4,e32,m1
	vlwu.v	v2,0(a5)
	vlwu.v	v1,0(a6)
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,s3
	vsll.vx	v1,v1,s2
	vor.vv	v1,v2,v1
	vsw.v	v1,0(a6)
	vsetvli	a1,a3,e32,m1
	vlwu.v	v2,0(a6)
	vlwu.v	v1,0(a2)
	vadd.vv	v1,v1,v2
	vsw.v	v1,0(a2)
	vsetvli	a1,a4,e32,m1
	vlwu.v	v2,0(a2)
	vlwu.v	v1,0(a7)
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,s1
	vsll.vx	v1,v1,s0
	vor.vv	v1,v2,v1
	vsw.v	v1,0(a7)
	vlwu.v	v1,0(a5)
	vlwu.v	v3,0(t4)
	vlxwu.v	v2,(a5),v3
	vsetvli	a1,a3,e32,m1
	vadd.vv	v1,v1,v2
	vsw.v	v1,0(a5)
	vsetvli	a1,a4,e32,m1
	vlwu.v	v2,0(a5)
	vlwu.v	v3,0(t3)
	vlxwu.v	v1,(a5),v3
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,t0
	vsll.vx	v1,v1,t0
	vor.vv	v1,v2,v1
	vsxw.v	v1,(a5),v3
	vlwu.v	v2,0(t1)
	vsetvli	a1,a3,e32,m1
	vlxwu.v	v1,(a5),v2
	vsetvli	a1,a4,e32,m1
	vlwu.v	v4,0(t3)
	vsetvli	a1,a3,e32,m1
	vlxwu.v	v3,(a5),v4
	vadd.vv	v1,v1,v3
	vsxw.v	v1,(a5),v2
	vsetvli	a1,a4,e32,m1
	vlwu.v	v1,0(t1)
	vlxwu.v	v2,(a5),v1
	vlwu.v	v3,0(t4)
	vlxwu.v	v1,(a5),v3
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,s5
	vsll.vx	v1,v1,s4
	vor.vv	v1,v2,v1
	vsxw.v	v1,(a5),v3
	vsetvli	a1,a3,e32,m1
	vlwu.v	v1,0(a5)
	vsetvli	a1,a4,e32,m1
	vlwu.v	v3,0(t4)
	vsetvli	a1,a3,e32,m1
	vlxwu.v	v2,(a5),v3
	vadd.vv	v1,v1,v2
	vsw.v	v1,0(a5)
	vsetvli	a1,a4,e32,m1
	vlwu.v	v2,0(a5)
	vlwu.v	v3,0(t3)
	vlxwu.v	v1,(a5),v3
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,s3
	vsll.vx	v1,v1,s2
	vor.vv	v1,v2,v1
	vsxw.v	v1,(a5),v3
	vlwu.v	v2,0(t1)
	vsetvli	a1,a3,e32,m1
	vlxwu.v	v1,(a5),v2
	vsetvli	a1,a4,e32,m1
	vlwu.v	v4,0(t3)
	vsetvli	a1,a3,e32,m1
	vlxwu.v	v3,(a5),v4
	vadd.vv	v1,v1,v3
	vsxw.v	v1,(a5),v2
	vsetvli	a1,a4,e32,m1
	vlwu.v	v1,0(t1)
	vlxwu.v	v2,(a5),v1
	vlwu.v	v3,0(t4)
	addiw	t2,t2,-1
	vlxwu.v	v1,(a5),v3
	vxor.vv	v1,v1,v2
	vsrl.vx	v2,v1,s1
	vsll.vx	v1,v1,s0
	vor.vv	v1,v2,v1
	vsxw.v	v1,(a5),v3
	bne	t2,zero,.L2
	lw	a5,0(s7)
	lw	a4,0(sp)
	addw	a5,a5,a4
	sw	a5,0(s6)
	lw	a4,4(s7)
	lw	a5,4(sp)
	addw	a5,a5,a4
	sw	a5,4(s6)
	lw	a4,8(s7)
	lw	a5,8(sp)
	addw	a5,a5,a4
	sw	a5,8(s6)
	lw	a4,12(s7)
	lw	a5,12(sp)
	addw	a5,a5,a4
	sw	a5,12(s6)
	lw	a4,16(s7)
	lw	a5,16(sp)
	addw	a5,a5,a4
	sw	a5,16(s6)
	lw	a4,20(s7)
	lw	a5,20(sp)
	addw	a5,a5,a4
	sw	a5,20(s6)
	lw	a4,24(s7)
	lw	a5,24(sp)
	addw	a5,a5,a4
	sw	a5,24(s6)
	lw	a4,28(s7)
	lw	a5,28(sp)
	addw	a5,a5,a4
	sw	a5,28(s6)
	lw	a4,32(s7)
	lw	a5,32(sp)
	addw	a5,a5,a4
	sw	a5,32(s6)
	lw	a4,36(s7)
	lw	a5,36(sp)
	addw	a5,a5,a4
	sw	a5,36(s6)
	lw	a4,40(s7)
	lw	a5,40(sp)
	addw	a5,a5,a4
	sw	a5,40(s6)
	lw	a4,44(s7)
	lw	a5,44(sp)
	addw	a5,a5,a4
	sw	a5,44(s6)
	lw	a4,48(s7)
	lw	a5,48(sp)
	addw	a5,a5,a4
	sw	a5,48(s6)
	lw	a4,52(s7)
	lw	a5,52(sp)
	addw	a5,a5,a4
	sw	a5,52(s6)
	lw	a4,56(s7)
	lw	a5,56(sp)
	addw	a5,a5,a4
	sw	a5,56(s6)
	lw	a4,60(s7)
	lw	a5,60(sp)
	addw	a5,a5,a4
	sw	a5,60(s6)
	ld	ra,136(sp)
	.cfi_restore 1
	ld	s0,128(sp)
	.cfi_restore 8
	ld	s1,120(sp)
	.cfi_restore 9
	ld	s2,112(sp)
	.cfi_restore 18
	ld	s3,104(sp)
	.cfi_restore 19
	ld	s4,96(sp)
	.cfi_restore 20
	ld	s5,88(sp)
	.cfi_restore 21
	ld	s6,80(sp)
	.cfi_restore 22
	ld	s7,72(sp)
	.cfi_restore 23
	addi	sp,sp,144
	.cfi_def_cfa_offset 0
	jr	ra
	.cfi_endproc
.LFE22951:
	.size	_Z8chacha20P10chacha_bufPKj, .-_Z8chacha20P10chacha_bufPKj
	.section	.rodata
	.align	3
	.set	.LANCHOR0,. + 0
	.type	_ZL1p, @object
	.size	_ZL1p, 48
_ZL1p:
	.word	20
	.word	24
	.word	28
	.word	16
	.word	40
	.word	44
	.word	32
	.word	36
	.word	60
	.word	48
	.word	52
	.word	56
	.ident	"GCC: (Xuantie-900 linux-5.10.4 glibc gcc Toolchain V2.6.1 B-20220906) 10.2.0"
	.section	.note.GNU-stack,"",@progbits
